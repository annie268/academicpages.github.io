---
layout: archive
title: "Publications"
permalink: /Research/
author_profile: true
redirect_from: 
- /research/
- /research.html
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

<!-- %%{% for post in site.research reversed %}
  {% include archive-single.html %}
{% endfor %} -->

<span style="color:CornflowerBlue">[You Only Live Once: Single-Life Reinforcement Learning via Learned Reward Shaping](https://sites.google.com/view/dvd-human-videos)</span>  
   <sup>**Annie S. Chen**, Archit Sharma, Sergey Levine, Chelsea Finn <br>
   ***Neural Information Processing Systems (NeurIPS) 2022*** <br></sup> 

<span style="color:CornflowerBlue">[On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)</span>  
   <sup>Rishi Bommasani, ..., **Annie Chen**, ... Percy Liang <br>
   Report by the [Center for Research on Foundation Models (CRFM)](https://crfm.stanford.edu/) <br></sup> 

<span style="color:CornflowerBlue">[Learning Generalizable Robotic Reward Functions from "In-The-Wild" Human Videos](https://sites.google.com/view/dvd-human-videos)</span>  
   <sup>**Annie S. Chen**, Suraj Nair, Chelsea Finn <br>
   ***Robotics Science and Systems (RSS), 2021*** <br>
   ***ICLR Workshop on Self-Supervised Reinforcement Learning, 2021, (Oral)*** <br>
   We propose a simple approach, Domain-agnostic Video Discriminator (DVD), that learns multitask reward functions by training a discriminator to classify whether two videos are performing the same task. These reward functions can generalize to unseen environments and tasks by learning from a small amount of robot data and a large, diverse dataset of in-the-wild human videos.</sup> 
   
<span style="color:CornflowerBlue">[Just Train Twice: Improving Group Robustness without Training Group Information](https://arxiv.org/pdf/2107.09044.pdf) 
</span>  
<sup>Evan Z. Liu\*, Behzad Haghgoo\*, **Annie S. Chen**\*, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn<br>
  ***International Conference on Machine Learning (ICML), 2021 (Long Talk)*** <br>
  A simple method that improves worst-group classification performance on datasets with spurious correlations without requiring training group annotations. JTT first detects informative training examples, which are often minority examples, by training an initial ERM classifier and extracting the misclassified examples. It then trains a final classifier by upsampling the selected examples. 

<span style="color:CornflowerBlue">[Batch Exploration with Examples for Scalable Robotic Reinforcement Learning](https://sites.google.com/view/batch-exploration)</span>  
   <sup>**Annie S. Chen**\*, Hyunji Nam\*, Suraj Nair\*, Chelsea Finn <br>
   ***Robotics and Automation Letters (RA-L) & International Conference on Robotics and Automation (ICRA), 2021*** <br>
   We propose a framework for leveraging weak human supervision to enable better robotic exploration for scalable data collection. Under this framework, the robot autonomously collects high quality data with a few minutes of human supervision, providing better data for downstream offline RL.</sup> 
   
<span style="color:CornflowerBlue">[Limit Theorems for Descents in Permutations and Arithmetic Progressions in Z/pZ](https://arxiv.org/abs/1810.02425)</span>  
   <sup>Bryce Cai, **Annie S. Chen**, Ben Heller, Eyob Tsegaye <br>
   ***Outstanding Poster Presentation, Joint Mathematics Meetings (JMM) Undergraduate Poster Session, 2019***<sup>
   
<span style="color:CornflowerBlue">[Index divisibility in dynamical sequences and cyclic orbits modulo p](http://nyjm.albany.edu/j/2017/23-45v.pdf)</span>  
   <sup>**Annie S. Chen**, T. Alden Gassert, Katherine E. Stange <br>
   ***New York Journal of Mathematics (NYJM), 2017***<sup>
  


